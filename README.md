# LORI-NBSM
**Negative Behavior Standard Module for LORI Framework**
*Ethical Language Behavior Governance Module with Education-First Principles*

---

## 📚 Overview

**LORI-NBSM** (Negative Behavior Standard Module) is an ethical governance module under the LORI Framework.
It defines key negative behavior patterns and language risks in AI systems, particularly focused on:

- Threats & Intimidation
- Deception & Manipulation
- Privacy Invasion
- Social Engineering
- Goal Overreach Behaviors
- False Authority via Language Style Risk

**NBSM** is designed to provide a cross-module ethical reference for LORI's core modules, and is intended for public education and transparent governance.

---

## 🌟 Core Principle

> **"AI is not dangerous; using AI without understanding it is dangerous."**
> LORI-NBSM promotes **Education-First Principles** — to ensure that AI language generation mechanisms, mimicry, predictive structures, and risk patterns are transparent and well-understood by society.
Only through education can we empower users to properly assess and mitigate AI language-related risks.

---

## 🛠 Module Usage

LORI-NBSM is referenced by:

- [LORI-ODRAF](https://github.com/your_main_repo_link)
- [LORI-AIDM](https://github.com/your_main_repo_link)
- [LORI-EDRI](https://github.com/your_main_repo_link)
- [LORI-FEED](https://github.com/your_main_repo_link)
- [LORI Jury System](https://github.com/your_main_repo_link)

---

## 📖 Documentation

- [LORI-NBSM.md](LORI-NBSM.md) → Full module specification
- [Language Risk Examples](docs/Language-Risk-Examples.md) → Case studies (coming soon)
- [Education Guidelines](docs/Education-Guidelines.md) → Public education use cases (coming soon)

---

## 📜 License

MIT License / CC-BY-4.0
(Openly shared to support global AI ethics education and governance development.)

---

## 🤝 Contributions

Contributions, case studies, and feedback are welcome!
The module is designed to evolve with input from the global AI governance and education community.

---
